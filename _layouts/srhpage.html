---
layout: default
---

<h4 class="post-title">SRH workflow</h4>

<div class="srh-workflow-image">
  <img src="/assets/images/srh-workflow.png" alt="srh-workflow" />
</div>
<div class="srh-workflow-description">
  <p>
    <b>Placeholder text:</b> Stimulated Raman histology (SRH) and
    contrastive representation learning framework. (A) Our clinical
    SRH imager used for intraoperative imaging of fresh brain tumor
    specimens. SRH images are obtained by imaging at two Raman shifts:
    2,845 cm-1 and2,950 cm-1. Lipid-rich regions (for example,
    myelinated white matter) demonstrate high SRS signal at 2,845 cm-1
    due to CH2 symmetric stretching in fatty acids. Cellular regions
    produce high 2,930 cm-1 intensity and large 2,930 : 2,845 ratios
    to high protein and nucleic acid content. The subtracted image
    highlights cellularity and nuclei. A virtual H&E color scheme is
    applied to transform the raw stimulated Raman scattering images
    into SRH images for clinical use and pathologic review.
    <b>(B)</b> Contrastive representation learning involves selecting
    a pair of positive image examples. In the self-supervised setting,
    this pair is generated by sampling two random transformations from
    a set of transformations, T , such as image blurring (t1) or
    flipping (t2), and applying the transformations to a single image,
    x, to get x1 and x2. Both images undergo a feed-forward pass
    through an SRH feature extractor, which is a convolutional neural
    network. x1 and x2 now have normalized vector representations, z1
    and z2, which can then be compared using a similarity metric on
    the unit hypersphere. The objective of contrastive learning is to
    make the similarity metric between positive examples large and
    negative examples small. This corresponds to placing
    representations of positive pairs in close proximity to each other
    and pushing negative pairs away. In the case of supervised
    contrastive learning, positive examples are pairs from the same
    diagnostic class and negative examples are from all other classes.
    (C) Finally, after training our SRH feature extractor using
    contrastive learning, we train a linear classification layer to
    provide a probability distribution over our output classes.
  </p>
</div>